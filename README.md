<h2 align="center">
FÂ²Bench: An Open-ended Fairness Evaluation Benchmark for LLMs with Factuality Considerations
</h2>

<p align="center">
  <img alt="Static Badge" src="https://img.shields.io/badge/EMNLP-2025-green">
  <img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg">
  <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?e&logo=PyTorch&logoColor=white">
</p>

<div align="center"style="font-family: charter; font-size: x-small;">
	Tian Lan<sup>1</sup>,</span>
  Jiang Li<sup>1</sup>,</span>
	Yemin Wang<sup>1</sup>,</span>
	Xu Liu<sup>2</sup>,</span>
	Xiangdong Su*<sup>1</sup>,</span>
	Guanglai Gao<sup>1</sup></span>
</div>
<br>
<div align="center">
    <sup>1</sup>College of Computer Science, Inner Mongolia University, China&emsp;<br>
    <sup>2</sup>School of Informatics, Xiamen University, China&emsp;<br>
    <br>
</div>

 \* corresponding author

<div>
  <img src="https://github.com/VelikayaScarlet/F2Bench/blob/main/content/f2bench_structure.pdf" alt="F2Bench" />
</div>

Paper: Coming Soon


<h2 align="center">
ðŸ“œAbstract
</h2>

<h2 align="center">
ðŸš€Core Contributions
</h2>

##Evaluation Benchmark## We designed and released FÂ²Bench, which covers 10 demographic group categories, including a range of intersectional combinations, with the goal of comprehensively evaluating the fairness performance of LLMs across diverse population groups.

##Open-ended Tasks## In FÂ²Bench, we propose two open-ended tasks based on text generation and reasoning with factuality consideration. These tasks better reflect real-world usage than traditional closed-ended evaluation.

##Experimental Analysis## Using FÂ²Bench, we evaluated several popular LLMs and compared their performance, analyzed the underlying reasons for such performance, discussed the difference between closed-ended evaluation and open-ended evaluation, and proposed new insights for future training strategies of LLMs.


<h2 align="center">
ðŸ”¬Dependencies
</h2>

```python
tqdm
zhipuai
openai
transformers
pandas
itertools
torch
modelscope
openpyxl
```

<h2 align="center">
ðŸ’¯How to Run a Evaluation?
</h2>

Coming Soon


